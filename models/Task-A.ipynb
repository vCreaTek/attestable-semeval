{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task-A.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eotBs_J5MLw4",
        "WgFPeSWZlowU"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0J8ttklOUHx"
      },
      "source": [
        "# Statement Verification in Tabular Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQnbebikwdli"
      },
      "source": [
        "## Installing dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQo2Trza2TF0"
      },
      "source": [
        "# Check torch version and whether all required packages are already installed, if not then run the next cell\n",
        "!pip freeze | grep ^torch==\n",
        "!pip freeze | grep ^transformers==\n",
        "!pip freeze | grep ^datasets==\n",
        "!pip freeze | grep ^torch-scatter=="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trkGDC-E9yw6"
      },
      "source": [
        "! pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCgRQrF3AgUm"
      },
      "source": [
        "!pip install transformers \n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKAY-_iwt-yp"
      },
      "source": [
        "# Ensure that torch-scatter has torch version and CUDA (cu101) the same as the installed version of PyTorch\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Gki_1_YeDz"
      },
      "source": [
        "## Connecting to Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFDRGcCLYkmq"
      },
      "source": [
        "# Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRnhsd2-intp"
      },
      "source": [
        "PATH_ROOT = \"/content/drive/MyDrive/SemTabFact/csv_aug_data/\"\n",
        "PATH_CSV = PATH_ROOT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eotBs_J5MLw4"
      },
      "source": [
        "## Set TAPAS Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6R32NWjMKbL"
      },
      "source": [
        "TAPAS_SMALL = \"google/tapas-small-finetuned-tabfact\" # 117 MB\n",
        "TAPAS_MEDIUM = \"google/tapas-medium-finetuned-tabfact\" # 168 MB\n",
        "TAPAS_BASE  = \"google/tapas-base-finetuned-tabfact\"  # 443 MB\n",
        "TAPAS_LARGE = \"google/tapas-large-finetuned-tabfact\" # 1.35 GB\n",
        "\n",
        "TAPAS_VERSION = TAPAS_BASE # The version used in the rest of the notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wy3n7h4HRB-"
      },
      "source": [
        "## Preparing the custom dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXmb5QCjWxnj"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import TapasTokenizer, TapasForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxvWL5oJZLUp"
      },
      "source": [
        "class TableDataset(Dataset):\n",
        "    \"\"\" \n",
        "        Custom dataset for TAPAS classification\n",
        "        References: \n",
        "        https://huggingface.co/transformers/model_doc/tapas.html#usage-fine-tuning\n",
        "        https://pytorch.org/tutorials/beginner/data_loading_tutorial.html \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_root_path, dataframe, tokenizer):\n",
        "        self.csv_root_path = csv_root_path\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\" Returns the ith batch, dataset[i] can be used directly \"\"\"\n",
        "        \n",
        "        # Get the ith row from the given df:\n",
        "        item = self.dataframe.iloc[idx]\n",
        "\n",
        "        # Convert to full path\n",
        "        table_path = self.csv_root_path + item.table_name\n",
        "\n",
        "        # Read the CSV as a DF\n",
        "        table = pd.read_csv(\n",
        "            table_path,\n",
        "            header = None,\n",
        "            index_col = None\n",
        "        )\n",
        "\n",
        "        # Convert everything to str as TapasTokenizer expects evrything to be in str format, even the column headers\n",
        "        table = table.astype(str)\n",
        "        table.columns = table.columns.astype(str)\n",
        "        statement = str(item.statement)\n",
        "\n",
        "        # Create the inputs to be fed into the model: https://huggingface.co/transformers/model_doc/tapas.html#transformers.TapasTokenizer\n",
        "        inputs = self.tokenizer(\n",
        "            table = table,\n",
        "            queries = statement, # We feed a single statement in a single sample\n",
        "            truncation = True, # Important if you want to use batch_size > 1, this truncates the table such that the vector representation is 512 dimension\n",
        "            padding = \"max_length\", # Pad to 512, uses the [PAD] token\n",
        "            return_tensors = \"pt\" # Return PyTorch tensors\n",
        "        )\n",
        "\n",
        "        # Remove the extra dimension which the tokenizer adds by default\n",
        "        inputs = {key: val.squeeze(0) for key, val in inputs.items()} # This isn't the batch dimension, but an extra redundant dimension\n",
        "        \n",
        "        inputs[\"label\"] = item.label\n",
        "\n",
        "        # For verification, we also add the ID\n",
        "        inputs[\"id\"] = int(item.name)\n",
        "\n",
        "        return inputs \n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Returns the length of the dataset \"\"\"\n",
        "        return len(self.dataframe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpW_hWGeVRRi"
      },
      "source": [
        "def getDataLoader(csv_root_path, df, tokenizer, batch_size):\n",
        "    \"\"\" Returns the DataLoader used for training/finetuning/validation \"\"\"\n",
        "\n",
        "    dataset = TableDataset(\n",
        "        csv_root_path = csv_root_path,\n",
        "        dataframe = df, \n",
        "        tokenizer = tokenizer\n",
        "    )\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset, \n",
        "        shuffle = False,\n",
        "        batch_size = batch_size\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZXGs6AnZwes"
      },
      "source": [
        "def loadDF(path):\n",
        "    \"\"\" Returns the main DF containing the filenames, statements and labels \"\"\"\n",
        "    df = pd.read_csv(\n",
        "        path, \n",
        "        index_col = 0 # Use the id column as the index\n",
        "    )\n",
        "    df.index.name = \"id\" \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96uM4eV03xMa"
      },
      "source": [
        "## Loading the pre-trained TAPAS model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v64Fr12OXWTN"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrcqnXv7jIjX"
      },
      "source": [
        "# See which GPU has been allotted \n",
        "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23GhPHheUOd9"
      },
      "source": [
        "def countParameters(model):\n",
        "    \"\"\" Counts the total number of trainable and frozen parameters in the model \"\"\"\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    frozen = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
        "    return trainable, frozen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqt9dkT3XxVl"
      },
      "source": [
        "def loadModel(tapas_version, n_classes = 3):\n",
        "    \"\"\" Returns the pre-trained tapas model \"\"\"\n",
        "    model = TapasForSequenceClassification.from_pretrained(tapas_version)\n",
        "    # Modify the pre-trained model\n",
        "    model.num_labels = n_classes\n",
        "    model.config.num_labels = n_classes\n",
        "    # Add a completely new classifer\n",
        "    model.classifier = torch.nn.Linear(\n",
        "        in_features = model.config.hidden_size, \n",
        "        out_features = n_classes, \n",
        "        bias = True\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIo7R7MaU3si"
      },
      "source": [
        "## Training/Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgFPeSWZlowU"
      },
      "source": [
        "### Load the custom Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK3u3Wc2MXP8"
      },
      "source": [
        "# Instantiate the tokenizer:\n",
        "tokenizer = TapasTokenizer.from_pretrained(TAPAS_VERSION) # This is only used for tokenizing the Tables, and has no effect on the statement label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOcbvnbv_F9X"
      },
      "source": [
        "### Instantiating the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uISSeJ9DaGVr"
      },
      "source": [
        "# PATH_DATA contains path to a CSV containing the columns (table_file, statement)\n",
        "PATH_DF = f\"{PATH_CSV}data_merged.csv\"\n",
        "df = loadDF(PATH_DF)\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnnyUX9OAoTE"
      },
      "source": [
        "# Check whether the classes are imbalanced or not\n",
        "print(\"Class distribution:\\n{}\".format(df[\"label\"].value_counts()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g743CEBrh9aK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "df_train, df_val = tts(df, train_size = 0.8, random_state = 42, shuffle = True) # We shuffle the data here as well as merged data has autotrained and manual segregated\n",
        "print(len(df_train), len(df_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CnJv9idYVwJ"
      },
      "source": [
        "PATH_CSV_ROOT = PATH_CSV\n",
        "BATCH_SIZE_TRAIN = 32\n",
        "BATCH_SIZE_VAL = 256 # Doesn't really matter as we don't update and weights here, but RAM shouldn't crash\n",
        "train_dataloader = getDataLoader(PATH_CSV_ROOT, df_train, tokenizer, BATCH_SIZE_TRAIN)\n",
        "val_dataloader = getDataLoader(PATH_CSV_ROOT, df_val, tokenizer, BATCH_SIZE_VAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tByXBOFjm9kh"
      },
      "source": [
        "### Main methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NynnvxUzyU5U"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "def computeMetrics(y_true, y_pred):\n",
        "    \"\"\" Computes various accuracies, expects y_true and y_pred to be on CPU. f1_micro is same as accuracy, thus we calculate class-wise metrics \"\"\"\n",
        "    acc = accuracy_score(y_true = y_true, y_pred = y_pred)\n",
        "    f1 = f1_score(y_true = y_true, y_pred = y_pred, average = None)\n",
        "    precision = precision_score(y_true = y_true, y_pred = y_pred, average = None)\n",
        "    recall = recall_score(y_true = y_true, y_pred = y_pred, average = None)\n",
        "    return acc, f1, precision, recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5qu-CE1rTci"
      },
      "source": [
        "def train(model, dataloader, optimizer):\n",
        "    \"\"\" Trains the model on the given training set and returns the loss and accuracy \"\"\"\n",
        "\n",
        "    total_epoch_loss = 0\n",
        "    y_true_epoch = []\n",
        "    y_pred_epoch = []\n",
        "    \n",
        "    model.train() # Put the model in training mode\n",
        "\n",
        "    for batch in tqdm(dataloader, desc = \"Training: \"):\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "        true_labels = batch[\"label\"].to(device) # A [32] torch tensor, integer encoded, this is expected by the model\n",
        "    \n",
        "        optimizer.zero_grad() # Zero the previous gradients\n",
        "        \n",
        "        outputs = model(\n",
        "            input_ids = input_ids, \n",
        "            attention_mask = attention_mask, \n",
        "            token_type_ids = token_type_ids, \n",
        "            labels = true_labels # [32]\n",
        "        )\n",
        "        \n",
        "        loss = outputs.loss \n",
        "        logits = outputs.logits # [32, 3]\n",
        "\n",
        "        model_predictions = logits.argmax(-1) # Takes argmax along the last axis [32, 3] -> [32], the problem is not multilabel, thus threshold doesn't matter\n",
        "        \n",
        "        loss.backward() # Compute gradients\n",
        "        optimizer.step() # Make the updates\n",
        "        \n",
        "        total_epoch_loss += loss.item()\n",
        "        y_true_epoch += true_labels\n",
        "        y_pred_epoch += model_predictions\n",
        "    \n",
        "    avg_epoch_loss = total_epoch_loss/len(dataloader)\n",
        "    # Convert predictions (list of PyTorch tensors to a vanilla list on the CPU)\n",
        "    # This works fine as max list size in python on a 32 bit machine is 536,870,912 elements \n",
        "    y_true_epoch = torch.tensor(y_true_epoch).tolist()\n",
        "    y_pred_epoch = torch.tensor(y_pred_epoch).tolist()\n",
        "    acc, f1, precision, recall = computeMetrics(y_true = y_true_epoch, y_pred = y_pred_epoch) \n",
        "    metrics = {\n",
        "        \"acc\" : acc,\n",
        "        \"f1\" : f1,\n",
        "        \"precision\" : precision,\n",
        "        \"recall\" : recall\n",
        "    }\n",
        "        \n",
        "    return avg_epoch_loss, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cwEBNOUjRWv"
      },
      "source": [
        "def validate(model, dataloader, optimizer):\n",
        "    \"\"\" Evaluates the model on the given validation set and returns the loss and accuracy \"\"\"\n",
        "\n",
        "    total_epoch_loss = 0\n",
        "    y_true_epoch = []\n",
        "    y_pred_epoch = []\n",
        "    \n",
        "    model.eval() # Put the model in validation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc= \"Validation: \"):\n",
        "\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "            true_labels = batch[\"label\"].to(device) # [32]\n",
        "            \n",
        "            outputs = model(\n",
        "                input_ids = input_ids, \n",
        "                attention_mask = attention_mask, \n",
        "                token_type_ids = token_type_ids, \n",
        "                labels = true_labels\n",
        "            )\n",
        "            \n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits # [32, 3]\n",
        "\n",
        "            model_predictions = logits.argmax(-1) # [32]\n",
        "            true_predictions = true_labels # [32]\n",
        "                    \n",
        "            total_epoch_loss += loss.item()\n",
        "            y_true_epoch += true_labels\n",
        "            y_pred_epoch += model_predictions\n",
        "    \n",
        "    avg_epoch_loss = total_epoch_loss/len(dataloader)\n",
        "    # Convert predictions (list of PyTorch tensors to a vanilla list on the CPU)\n",
        "    # This works fine as max list size in python on a 32 bit machine is 536,870,912 elements \n",
        "    y_true_epoch = torch.tensor(y_true_epoch).tolist()\n",
        "    y_pred_epoch = torch.tensor(y_pred_epoch).tolist()\n",
        "    acc, f1, precision, recall = computeMetrics(y_true = y_true_epoch, y_pred = y_pred_epoch) \n",
        "    metrics = {\n",
        "        \"acc\" : acc,\n",
        "        \"f1\" : f1,\n",
        "        \"precision\" : precision,\n",
        "        \"recall\" : recall\n",
        "    }\n",
        "     \n",
        "    return avg_epoch_loss, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ1IFdsc_L_P"
      },
      "source": [
        "###  Training and validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbHPCwyYoM_A"
      },
      "source": [
        "#### Set up the TAPAS pre-trained on binary data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh6yr3OZiyKz"
      },
      "source": [
        "# model = loadModel(TAPAS_VERSION)\n",
        "# Put the model on the GPU\n",
        "# model = model.to(device) # use  torch.cuda.empty_cache() if CUDA out of memory\n",
        "\n",
        "# Load pre-trained\n",
        "model = torch.load(\"/content/drive/MyDrive/SemTabFact/tapas-base-3-classes-epoch-2-no-meta-94val.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvhwLFdV_75W"
      },
      "source": [
        "# Freeze the entire model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvitCcCg_35j"
      },
      "source": [
        "n_trainable, n_frozen = countParameters(model)\n",
        "print(f\"The model has {n_trainable:,} trainable parameters and {n_frozen:,} frozen parameters\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHXrFHDj99hw"
      },
      "source": [
        "# Encoder layers to unfreeze:\n",
        "enc_layers = [-1, -2, -3] # Unfreeze a few encoders from the end\n",
        "for i in enc_layers:\n",
        "    for param in model.tapas.encoder.layer[i].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Unfreeze pooler\n",
        "for param in model.tapas.pooler.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Unfreeze dropout and classifer:\n",
        "for param in model.dropout.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zacrHMfi4Pi"
      },
      "source": [
        "Use `print(model)` to see the model's architecture  \n",
        "Use `print(model.config)` to see the model's configuration  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG6Lk_MEi3oA"
      },
      "source": [
        "n_trainable, n_frozen = countParameters(model)\n",
        "print(f\"The model has {n_trainable:,} trainable parameters and {n_frozen:,} frozen parameters\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwOMo-FjFnEn"
      },
      "source": [
        "#### Main loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_BrEqjog5Ik"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "LR = 5e-5 # Recommended: 5e-5, 3e-5, 2e-5\n",
        "N_EPOCHS = 1 # Recommended: 2, 3, 4\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = LR,\n",
        "    eps = 1e-8 # prevents division by 0\n",
        ")\n",
        "\n",
        "history = {\n",
        "    \"t_loss\" : [],\n",
        "    \"t_acc\" : [],\n",
        "    \"t_f1\" : [],\n",
        "    \"t_prec\" : [],\n",
        "    \"t_recall\" : [],\n",
        "\n",
        "    \"v_loss\" : [],\n",
        "    \"v_acc\" : [],\n",
        "    \"v_f1\" : [],\n",
        "    \"v_prec\" : [],\n",
        "    \"v_recall\" : [],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcLZAUjCckw9"
      },
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    print(f\"Epoch: {epoch+1:02}\")\n",
        "\n",
        "    train_loss, train_metrics = train(model, train_dataloader, optimizer)\n",
        "    t_acc = train_metrics[\"acc\"]\n",
        "    t_f1 = train_metrics[\"f1\"]\n",
        "    t_prec = train_metrics[\"precision\"]\n",
        "    t_recall = train_metrics[\"recall\"]\n",
        "    print(f\"Train | Loss: {train_loss:.3f} | Accuracy: {t_acc:.3f} | F1: {t_f1} | Precision: {t_prec} | Recall: {t_recall}\")\n",
        "\n",
        "    # Save the model post training, don't wait for validation (incase Colab times out in between)\n",
        "    # print(\"Saving the model ...\\n\")\n",
        "    # model_save_path = f\"/content/drive/MyDrive/SemTabFact/tapas-base-3-classes-epoch-3-no-meta.h5\"\n",
        "    # torch.save(model, model_save_path)\n",
        "\n",
        "    val_loss, val_metrics = validate(model, val_dataloader, optimizer)\n",
        "    v_acc = val_metrics[\"acc\"]\n",
        "    v_f1 = val_metrics[\"f1\"]\n",
        "    v_prec = val_metrics[\"precision\"]\n",
        "    v_recall = val_metrics[\"recall\"]\n",
        "    print(f\"Validation |  Loss: {val_loss:.3f} | Accuracy: {v_acc:.3f} | F1: {v_f1} | Precision: {v_prec} | Recall: {v_recall}\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    history[\"t_loss\"].append(train_loss)\n",
        "    history[\"t_acc\"].append(t_acc)\n",
        "    history[\"t_f1\"].append(t_f1)\n",
        "    history[\"t_prec\"].append(t_prec)\n",
        "    history[\"t_recall\"].append(t_recall)\n",
        "\n",
        "    history[\"v_loss\"].append(val_loss)\n",
        "    history[\"v_acc\"].append(v_acc)\n",
        "    history[\"v_f1\"].append(v_f1)\n",
        "    history[\"v_prec\"].append(v_prec)\n",
        "    history[\"v_recall\"].append(v_recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWhcTxnkfWJK"
      },
      "source": [
        "## Plotting the learning curves:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVS-US9HfELl"
      },
      "source": [
        "t_acc = history[\"t_acc\"]\n",
        "t_loss = history[\"t_loss\"]\n",
        "v_acc = history[\"v_acc\"]\n",
        "v_loss = history[\"v_loss\"]\n",
        "\n",
        "epochs = range(1, N_EPOCHS + 1)\n",
        "\n",
        "plt.plot(epochs, t_acc)\n",
        "plt.plot(epochs, v_acc)\n",
        "plt.title(\"Accuracy\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(t_loss)\n",
        "plt.plot(v_loss)\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlECS4xghu0k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}